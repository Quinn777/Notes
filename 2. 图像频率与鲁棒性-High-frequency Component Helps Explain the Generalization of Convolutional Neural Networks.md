[toc]

论文地址：https://arxiv.org/abs/1905.13545

源码：https://github.com/HaohanWang/HFC

## 写在前面

泛化能力一直是DL领域老生长谈的问题，是否具有良好的鲁棒性早已成为评价一个模型好坏的重要指标，那么模型泛化能力差异的起源来自哪里？是什么导致了机器学习与人类学习能力的差异？这篇来自CVPR2020 Oral中的论文从数据的角度回答了这个问题，全文逻辑严密，亮点突出，十分具有研究意义。



## Abstract

本文探究了图片高频波段和卷积神经网络泛化性能的关系，作者发现图片高频部分人眼虽然无法辨别，但它和语义部分一样能够被模型感知。通过这种现象，作者探究了模型在对对抗样本分类时的可解释性，以及对启发式训练的新理解。

<img src="http://xiangkun-img.oss-cn-shenzhen.aliyuncs.com/20210818214035.png" alt="image-20210818214035543" style="zoom:50%;" />



## Introduction

神经网络的泛化性能具有强烈的非直观性，常常会产生与人类认知大相径庭的预测结果，具体体现在记忆标签混乱数据的缺陷以及面对对抗性示例时的脆弱性。

在下面的实验中描述了模型在对高频信息和低频信息的敏感度具有较大差异。图中每个实验的第一列表示原图，第二列为图像低频信息，第三列为图像高频信息，可以看到模型对语义信息较为明确的低频部分分类偏移很大，但对于人眼无法看清的高频部分却可以得到正确结果。

<img src="http://xiangkun-img.oss-cn-shenzhen.aliyuncs.com/20210818214013.png" alt="image-20210818214013404" style="zoom:50%;" />

### 贡献

- 探究模型准确率和鲁棒性的平衡
- 以图像频率波谱为工具，来探索神经网络对随机标签的数据的记忆能力
- 提供了一种防御方法，可以提升网络面对对抗攻击的鲁棒性



## Related work

### Label Shuffling

Label Shuffling是一种针对数据不均衡（imbalance）的数据增广方式，由海康威视在ILSVRC 2016中提出。

<img src="http://xiangkun-img.oss-cn-shenzhen.aliyuncs.com/20210818220306.png" alt="image-20210818220306844" style="zoom:50%;" />

<center>随机标签流程</center>

Label Shuffling可以由以下6步实现：

1. **Sorting**
   对batch（或者某个数据集）里的不均衡的样本按照label进行排序，并在每类中建立的id。
2. **Counting**
   统计每个类别的数量，并找到数量最多的样本的类别。
3. **Randperm (Random Permutation)**
   基于样本最多类别的样本数的随机打乱排序。假设当前batch一共有 ![[公式]](https://www.zhihu.com/equation?tex=M) 个类别，每个类别的样本数量为 ![[公式]](https://www.zhihu.com/equation?tex=N%3D\{N_1%2CN_2%2C...%2CN_M\})，其中样本数量最多的类别有 ![[公式]](https://www.zhihu.com/equation?tex=N_{max}%3Dmax(N)) 个样本，那么现在生成 ![[公式]](https://www.zhihu.com/equation?tex=M) 个 ![[公式]](https://www.zhihu.com/equation?tex=N_{max})维随机排序（randperm,RP），也就是 ![[公式]](https://www.zhihu.com/equation?tex=M) 个RP=numpy.random.permutation( ![[公式]](https://www.zhihu.com/equation?tex=N_%7Bmax%7D) )，即生成了 ![[公式]](https://www.zhihu.com/equation?tex=\{RP_1%2CRP_2%2C...%2CRP_M\}) 。
4. **Mod**
   对每个randperm做取模运算，模为该类的样本数。例如，对第 ![[公式]](https://www.zhihu.com/equation?tex=j) 类，它的样本数为 ![[公式]](https://www.zhihu.com/equation?tex=N_j) ，它的randomperm为 ![[公式]](https://www.zhihu.com/equation?tex=RP_j) ，所以它的取模运算结果为： ![[公式]](https://www.zhihu.com/equation?tex=S_j%3DRP_j+\%+N_j) 。
5. **Selecting**
   根据取模运算的结果进行重采样，使得每类样本的数量都为 ![[公式]](https://www.zhihu.com/equation?tex=N_%7Bmax%7D) 。按照 ![[公式]](https://www.zhihu.com/equation?tex=S_j) 取索引原本类中样本（按照样本id进行匹配），并复制到对应的位置上，从而得到 ![[公式]](https://www.zhihu.com/equation?tex=N_%7Bmax%7D) 个 ![[公式]](https://www.zhihu.com/equation?tex=M_j) 类样本。
6. **Concat & Shuffling**
   经过步骤5，每类都会有 ![[公式]](https://www.zhihu.com/equation?tex=N_%7Bmax%7D) 个样本，将所有样本（ ![[公式]](https://www.zhihu.com/equation?tex=M*N_{max}) )concatenate在一起，并打乱顺序，得到一个新的batch，此batch即为label shuffling增强后的batch。

> 参考https://zhuanlan.zhihu.com/p/116664645



## High-frequency Components & CNN’s Generalization

### 符号说明

<img src="http://xiangkun-img.oss-cn-shenzhen.aliyuncs.com/20210818220952.png" alt="image-20210818220952769" style="zoom:50%;" />



### CNN关注高频信息

#### 图像低频、高频划分

首先作者将图像分为高频部分(high-frequency component, HFC)和低频部分(low-frequency component, LFC)，具体做法如下：

<img src="http://xiangkun-img.oss-cn-shenzhen.aliyuncs.com/20210819145653.png" alt="image-20210819145653763" style="zoom:50%;" />

首先对图像x进行傅立叶变换，后将变换结果z通过一个超参数阈值r进行分割(t(z, r))，分割出的低频部分$z_l$经过傅立叶逆变换恢复为$x_l$，至此$x_l$就是要输入的图像低频部分了，高频同理。

#### 划分函数t(·; r) 的选择

<img src="http://xiangkun-img.oss-cn-shenzhen.aliyuncs.com/20210819154534.png" alt="image-20210819154534829" style="zoom:50%;" />

作者用$(c_i,c_j)$表示图像经傅立叶变换后的质心，在寻找低频信号时，如果点$(i,j)$到质心的距离小于r则结果不变，否则置为0；高频信号同理。

> 注意，在上式中的$z$均为单通道图像傅立叶变化后的结果，如为多通道需对每个通道进行上述操作。

#### 假设1

在这里作者提出了前文所说的假设模型，即人类只能识别低频部分图片的语义，而计算机同时考虑低频和高频信号。

<img src="http://xiangkun-img.oss-cn-shenzhen.aliyuncs.com/20210819161640.png" alt="image-20210819161328012" style="zoom:50%;" />

  <center>人类识别模型</center>

<img src="http://xiangkun-img.oss-cn-shenzhen.aliyuncs.com/20210819162011.png" alt="image-20210819162010979" style="zoom:50%;" />

<center>神经网络识别模型</center>

作者认为虽然CNN考虑高频信号会导致与人眼分辨产生偏差的结果，但这种特性与过拟合不同，因为高频部分可以包含比样本语义特征更多的信息，并且这些更多的信息可以在训练、验证和测试中集中概括，只是人类无法察觉罢了。

#### 对泛化性能的影响

- 对抗样本可以通过扰动高频信号来产生
- CNN通过lable shuffled data来减少训练误差可以看作是网络利用高频信号和过度拟合样本特质的结果。



### 鲁棒性和准确率的权衡

在这里作者定义了accuracy和robustness

1. accuracy表示样本集里x测试准确率的期望

<img src="http://xiangkun-img.oss-cn-shenzhen.aliyuncs.com/20210819174936.png" alt="image-20210819174936063" style="zoom:50%;" />

2. robustness表示在给定扰动样本$x’$，且让其扰动范围小于阈值*ϵ*时，不同扰动产生的最小准确率的期望

<img src="http://xiangkun-img.oss-cn-shenzhen.aliyuncs.com/20210819175040.png" alt="image-20210819175040518" style="zoom:50%;" />

#### 假设2

对于给定的模型$\theta$，一定存在样本$<x, y>$满足$f(x;θ) \neq f(x_l;θ)$

#### 推论1

根据假设1和假设2，得出第一个推论：永远不能找到一个模型在所有样本下都能同时满足高准确率和高鲁棒性，这导致我们总需要在训练中权衡准确性和鲁棒性。



## Rethinking Data before Rethinking Generalization

### 猜想

之前的研究表明神经网络可以很容易地在混乱标签数据集上收敛，故作者发出了拷问：如果模型能很容易记住数据，那为什么还要从数据集中学习可泛化的特征，而不是直接记住所有数据来降低损失呢？

因此作者提出了猜想：

尽管与训练损失最小化的结果相同，但该模型在两种情况下考虑了不同级别的特征：

- 在自然标签数据集中，模型会优先学习 LFC（较快），然后逐渐学习 HFC，以达到更高的训练精度。
- 在混乱标签数据集中，由于标签被打乱，其和LFC 之间的关联被擦除，模型必须将LFC 和HFC 同等对待来学习（较慢）。

### 实验1

作者用resnet-18和cifar10进行实验，具体参数见论文。后又使用imagenet、mnist、fashion mnist进行测试，结果相同。

实验分为两组，分别是用自然标签和随机标签进行实验($M_{natural}$ and $M_{shuffle}$)。每组训练数据x采用r=4, 8, 12, 16来选择低频部分$x_l$，随后测试了当低频数据变化时准确率的变化情况。

<img src="http://xiangkun-img.oss-cn-shenzhen.aliyuncs.com/20210819201738.png" alt="image-20210819201738110" style="zoom:50%;" />

从上图的实验结果可以看出，自然样本训练时采用较低r值时分类效果比混乱样本好，因为高频信息减少了，这表明在自然样本训练时模型更加倾向于学习低频信息，而在混乱样本训练时模型更倾向于将两者同等对待（其实就是对高频信息更敏感）。

除此之外，随机标签组的收敛速度较慢，作者解释说这表明与学习可概括的模式相比，单纯记忆样本是一种“不自然”的行为 (which suggests that memorizing the samples as an “unnatural” behavior in contrast to learning the generalizable patterns. ) ，即认为在混乱样本数据集上训练的模型时倾向于**学习**样本特征而不是**记忆**样本特征。

### 再次猜想

从这次实验中作者又产生了这样一个疑惑：如果一个模型可以利用多个不同的信号波段，那么为什么 $M_{natural }$更喜欢学习恰好与人类感知偏好一致的低频信息？

对此作者再一次提出了猜想：

因为$M_{natural }$中的图片标注是人为操作的，标签与低频语义信息之间具有高度相关性，所以模型在自然标签环境下训练能够快速找到这种相关性，并在学习这种关联时让损失函数的下降梯度更陡峭，致使训练速度加快。

### 实验2

为了验证上述猜想，作者又进行了一组实验：

<img src="http://xiangkun-img.oss-cn-shenzhen.aliyuncs.com/20210819211303.png" alt="image-20210819211303319" style="zoom:50%;" />

本次实验只使用自然标签数据集，使用与实验一相同的参数进行实验，但将高频信息HFC也提取出来作为数据的输入来对比，而测试数据则采用原始图片。表中左边为输入LFC的结果，右边为HFC的结果。

显然表中数据表明在自然标签数据集中训练出来的模型对LFC测试准确率依然较高，表明学习低频信息可以得到更好的泛化能力，而对HFC测试时模型几乎完全失去作用了。因此，作者总结出：

在自然标签数据下模型更倾向于选择低频信号，因为此时loss函数下降的最快。



## Training Heuristics

作者在这部分评估了多种启发式算法对低频信息和高频信息的泛化性能

### 比较不同的启发式算法

#### 实验1-batch size

本实验主要探究batch size大小对泛化性能的影响。

![image-20210819220459101](http://xiangkun-img.oss-cn-shenzhen.aliyuncs.com/20210819220459.png)

图中可以看出较小的batch size能得到更高的训练和测试准确率，而较大的batch size得出来的训练准确率和测试准确率更为接近。同时较大batch size在高频信息增多时不变性增强，即准确率不会下降太低，

图 4 中的观察结果也有助于对上一节关于泛化特征的讨论。 直观地说，随着 epoch 大小的增加，导致损失函数下降最快的特征更有可能是数据的“可泛化”部分，即 LFC。

#### 实验2-不同的启发式算法

本实验分为以下多组，每组应用一个启发式算法：

- Dropout ：一种在训练期间随机降低权重的启发式方法。 作者在p = 0.5的全连接层上应用 dropout。
-  Mix-up ：一种在训练期间线性整合样本及其标签的启发式方法。 这里使用超参数α = 0.5。
-  BatchNorm ：一种对每个训练小批量执行归一化以加速深度网络训练过程的方法。 它允许我们使用更高的学习率来降低过拟合，这里将比例尺 γ 设置为 1 并将偏移量 β 设置为 0 。
- Adversarial Training：一种通过训练期间威胁模型生成的对抗性示例来扩充数据的方法。这里使用具有ε = 8/255 (ε = 0.03 ) 的PGD作为威胁模型。

实验结果如下：

![image-20210820144208154](http://xiangkun-img.oss-cn-shenzhen.aliyuncs.com/20210820144208.png)

图中可以看到DropOut对准确率影响不大，MixUp对准确率影响也不大，但捕捉了更多高频信息，因为在MixUp的时候并没有增加更多低频信息。

对抗训练的准确率较低，因为它是准确率和鲁棒性之间权衡的结果。但是优点是有更小的泛化差距，是由于其选择了泛化模式（generalizable patterns）。当r=12或16时对抗训练准确率变化不大，可能是此时对高频信息不敏感，然而，在r=4时对抗学习比普通训练法更注重高频信息（准确率下降的更多）。



除此之外，作者还尝试了其他启发式方法进行训练，包括：

**模型：**LeNet, AlexNet, VGG, ResNet

**优化器**：SGD, ADAM, AdaGrad, AdaDelta, RMSprop

作者并没有给出实验数据，只是从口头上描述了结果：

- ResNet 得到了更好的普通测试精度、更小的泛化差距（训练和测试精度之间的差异）以及对高频信息的捕获能力较差。

- 在所有优化器比较中SGD 是唯一一个对高频信息捕获能力较强的。



### 对Batch Normalization的猜想

基于对上述实验的观察，作者猜想 BatchNorm 的优势之一是通过归一化来对齐不同预测信号的分布差异，比如原本较少的高频信号在平衡之后会被模型更加重视，所以没有使用BatchNorm的模型更难捕捉高频信息。

为了验证猜想，作者将应用了Batch Norm和原始模型作为对比，分别测试对低频信号的分类准确率。

<img src="http://xiangkun-img.oss-cn-shenzhen.aliyuncs.com/20210820151838.png" alt="image-20210820151838746" style="zoom: 67%;" />

从实验结果可以看出BatchNorm对低频信号提取的帮助并不大，且r越小起到的提升就越少，甚至可能会降低准确率。不过，BN还是可以起到加速收敛的作用。

同时，通过对比发现r=4时性能改善最不明显，这也印证了前面的猜想：如果 BatchNorm 的优势之一是鼓励模型捕获不同的预测信号，那么 当 r = 4 时使用 LFC 训练模型时，BatchNorm 的性能增益最小。（此时输入的信号频率最低）



## Adversarial Attack & Defense

本节的主要内容为探究对抗鲁棒性和模型提取高频信息时的趋势。

- 首先作者讨论了卷积核的“平滑度”与模型对 HFC 的敏感性（第 6.1 节）之间的联系

- 证明对抗性鲁棒模型往往具有平滑的内核（第 6.2 节）
- 证明无需训练、直接平滑内核可以帮助我们提高对某些攻击的对抗性鲁棒性（第 6.3 节） .

### 核平滑度与图像频率

卷积理论表明，图像的卷积运算相当于图像频域的逐元素乘法。

因此，如果一个卷积核在HFC的权重可以忽略不计，它就会相应地对高频部分不予以重视。不过这可能只适用于第一层的卷积核，因为更高层的核不直接与数据相关。

另外，如果卷积核是“平滑的”，这意味着相邻权重之间没有剧烈的波动，那么相应的频域将看到可以忽略不计的高频信号。

所以作者据此提出，为了让模型忽略 HFC，可以考虑让模型学习在频域高端权重较低的卷积核，即更加平滑的卷积核。

### 鲁棒模型具有更平滑的卷积核

为了更清楚地展示核平滑度和鲁棒性之间的关系，作者可视化了自然训练下和对抗训练下模型第一层的卷积核。

<img src="http://xiangkun-img.oss-cn-shenzhen.aliyuncs.com/20210820173918.png" alt="image-20210820173917993" style="zoom:50%;" />

图中能看到采用对抗训练的结果明显颜色更加平均，它们的每个卷积核之间颜色更加接近、平滑。

### 平滑卷积核能提升鲁棒准确率

以上两部分讨论让作者产生疑问：更平滑的卷积核是否能提升鲁棒准确率？

作者使用FGSM和PGD来进行一系列对抗实验。将卷积核用$w_{i,j}$表示，其中$i,j$表示行、列。$\rho$表示超参数。此外，用$N(i,j)$表示i行j列点的领域空间。如果i, j在3*3卷积核的中间，则$N(i,j)$表示周围的8个节点，否则如果位于核的边缘，则使用邻接值复制作为出界的节点。

<img src="http://xiangkun-img.oss-cn-shenzhen.aliyuncs.com/20210820173220.png" alt="image-20210820173220012" style="zoom:50%;" />

<img src="http://xiangkun-img.oss-cn-shenzhen.aliyuncs.com/20210820174258.png" alt="image-20210820174258770" style="zoom:50%;" />

从可视化结果中可以看到使用这种平滑方法能让卷积核变得更为平滑，与此同时在准确率上也取得了一些效果。

<img src="http://xiangkun-img.oss-cn-shenzhen.aliyuncs.com/20210820175054.png" alt="image-20210820175054642" style="zoom:50%;" />

从表中可以看出，在应用该方法后模型对原始数据的分类准确率都下滑了，但面对添加干扰的对抗样本训练时却有提升（准确率与鲁棒性的权衡）。

值得注意的是，当扰动$\varepsilon$增大时该方法的作用更加明显（如$\rho=1.0，\varepsilon=0.09, PGD$时，$M_{natural}$的准确率甚至大于原始的$M_{adversarial}$）

总的来说我们的方法可以轻松提高 $M_{natural }$的对抗鲁棒性，但只能在$\varepsilon$较大的情况下改进 $M_{adversarial}$



## Beyond Image Classification

本章节作者探讨了上述发现在目标检测中的应用情况。

作者使用 RetinaNet和 ResNet50 + FPN 作为主干，并使用 COCO 检测训练集训练模型，并在其验证集中进行推理，实现了35.6%的MAP。

然后，作者选择 r = 128来划分低频部分与高频部分， 并使用相同的模型进行测试。这一次仅仅得到 27.5% 的 LFC MAP 和 10.7% 的 HFC MAP，性能从 35.6% 下降到 27.5% 。

### 低频部分上的性能下降

<img src="http://xiangkun-img.oss-cn-shenzhen.aliyuncs.com/20210820181807.png" alt="image-20210820181807049" style="zoom:50%;" />

因为和原图像相比，低频部分输入少了很多高频细节，所以此时目标检测性能下降是可以理解的。



### 低频部分上的性能提升

<img src="http://xiangkun-img.oss-cn-shenzhen.aliyuncs.com/20210820182412.png" alt="image-20210820182412774" style="zoom:50%;" />

与此同时在另外一部分图片上模型也获得了一些性能提升，作者认为这表明在除图像分类领域之外，CNN与人类感知图片的差异依然存在。



## Discussion: Are HFC just Noises?

看到这里可能大家会想，如果高频信号只是噪音，那我们只需要寻找一个良好的降噪策略就能实现准确率和鲁棒性的双丰收了。

但是事实果真如此吗，作者在实验尝试了一种常用的图像去噪方法：截断奇异值分解法（SVD）。降噪之后发现剩下的图像很少能被识别，故作者认为HFC不只是噪音。



## Conclusion & Outlook

本文从图像频谱的角度出发，探究其与模型泛化能力的关系，主要发现如下：

- CNN可能会学习图像中与人类感知不同的信息
- 一些用于提高准确率的启发式算法 (Mix-up and BatchNorm) 可能会刺激模型学习高频信息，因此我们需要对准确率和鲁棒性做一个权衡
- 在对抗样本中表现较强鲁棒性的模型往往具有平滑的卷积核，但反之并不总是如此
- 在目标检测中也得出相似的现象，但还没有进行深入研究

展望未来：

- 性能指标排行榜上的一个更好的数字虽然可以表明研究正在朝着一个方向发展，但并不能可靠地反映模型与人类之间的一致性，而这种一致性可以说是最重要的。
- 希望以后的工作能将低频对应物体的特征是否能被有效提取也作为指标，将其和原始图像的分类性能一起被纳入评估模型好坏的标准
- 考虑人类如何看待数据的显性归纳偏差（Explicit inductive bias）可能在未来发挥重要作用。 特别是，神经科学文献表明，人类在识别物体时倾向于依赖低频信号 ，这可能会激发未来方法的发展。